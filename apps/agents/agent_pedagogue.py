# apps/agents/agent_pedagogue.py

from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from apps.agents.tools.llm_loader import get_llm
from langchain_community.vectorstores import Chroma
from apps.rag.utils import load_embedding_function

def get_pedagogue_chain(model_name="llama3-70b-8192"):
    """
    Agent PÃ©dagogue : gÃ©nÃ¨re un mini-cours structurÃ© Ã  partir des documents retrouvÃ©s.
    """
    try:
        # Embeddings + vectorstore
        embedding_fn = load_embedding_function()
        vectorstore = Chroma(
            persist_directory="apps/rag/chroma",
            embedding_function=embedding_fn,
            collection_name="eduai_knowledge_base"
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        llm = get_llm(model_name=model_name)
    except Exception as e:
        print(f"Erreur lors de l'initialisation du pÃ©dagogue : {e}")
        # Fallback sans RAG
        llm = get_llm(model_name=model_name)
        retriever = None

    # Prompt de synthÃ¨se structurÃ©
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es un excellent pÃ©dagogue. Ã€ partir du contenu suivant, gÃ©nÃ¨re un mini-cours structurÃ©.

==== CONTEXTE ====
{context}

==== INSTRUCTION ====
Ã‰cris une leÃ§on pÃ©dagogique claire et concise pour rÃ©pondre Ã  la question suivante :
{question}

Ta rÃ©ponse doit inclure :
- ğŸ“– **Introduction** : PrÃ©sentation du concept
- ğŸ” **Explication dÃ©taillÃ©e** : ThÃ©orie et fonctionnement
- ğŸ’¡ **Exemples pratiques** : Code et cas d'usage concrets
- ğŸ“ **Points clÃ©s Ã  retenir** : RÃ©sumÃ© des Ã©lÃ©ments essentiels
- ğŸš€ **Pour aller plus loin** : Suggestions d'approfondissement

Utilise un ton pÃ©dagogique et structure bien ton contenu avec des sections claires.
"""
    )

    if retriever:
        return RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt}
        )
    else:
        # Fallback sans RAG
        from langchain.chains import LLMChain
        simple_prompt = PromptTemplate(
            input_variables=["question"],
            template="""
Tu es un excellent pÃ©dagogue en programmation. GÃ©nÃ¨re un mini-cours structurÃ© sur le sujet suivant :
{question}

Ta rÃ©ponse doit inclure :
- ğŸ“– **Introduction** : PrÃ©sentation du concept
- ğŸ” **Explication dÃ©taillÃ©e** : ThÃ©orie et fonctionnement  
- ğŸ’¡ **Exemples pratiques** : Code et cas d'usage concrets
- ğŸ“ **Points clÃ©s Ã  retenir** : RÃ©sumÃ© des Ã©lÃ©ments essentiels
- ğŸš€ **Pour aller plus loin** : Suggestions d'approfondissement

Utilise un ton pÃ©dagogique et structure bien ton contenu avec des sections claires.
"""
        )
        return LLMChain(llm=llm, prompt=simple_prompt)